{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1e0c5-c53b-4e36-b0c0-ebd2d24c1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Imports and Functions\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.ndimage import label\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import itertools\n",
    "\n",
    "# Configuration Parameters\n",
    "DIM = 3        # Base dimension for patches (3×3)\n",
    "POWER = 4      # Lattice size = DIM^POWER\n",
    "MAX_STEPS = POWER + 5  # Maximum coarse-graining steps\n",
    "\n",
    "def generate_percolation_lattice(size, p):\n",
    "    return np.random.choice([0, 1], (size, size), p=[1 - p, p])\n",
    "\n",
    "def check_percolation(lattice):\n",
    "    labeled, _ = label(lattice)\n",
    "    \n",
    "    # Vertical percolation (top-bottom)\n",
    "    top = set(labeled[0, :]) - {0}\n",
    "    bottom = set(labeled[-1, :]) - {0}\n",
    "    vertical = bool(top & bottom)\n",
    "    \n",
    "    # Horizontal percolation (left-right)\n",
    "    left = set(labeled[:, 0]) - {0}\n",
    "    right = set(labeled[:, -1]) - {0}\n",
    "    horizontal = bool(left & right)\n",
    "    \n",
    "    return float(vertical or horizontal)\n",
    "\n",
    "class PercolationModel(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.rule = nn.Sequential(\n",
    "            nn.Linear(dim * dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, max_steps=MAX_STEPS):\n",
    "        b, c, H, W = x.shape\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if H < self.dim or W < self.dim:\n",
    "                break\n",
    "            \n",
    "            # Extract dim×dim patches\n",
    "            patches = F.unfold(x, kernel_size=self.dim, stride=self.dim)\n",
    "            patches = patches.permute(0, 2, 1).contiguous()  # (B, #patches, dim*dim)\n",
    "            patches = patches.view(-1, self.dim * self.dim)   # (B * #patches, dim*dim)\n",
    "            \n",
    "            out = self.rule(patches)  # (B * #patches, 1)\n",
    "            \n",
    "            new_h, new_w = H // self.dim, W // self.dim\n",
    "            x = out.view(b, 1, new_h, new_w)  # (B, 1, new_h, new_w)\n",
    "            _, c, H, W = x.shape\n",
    "\n",
    "        return x.squeeze()  # (B,)\n",
    "\n",
    "def prepare_dataset(num_samples, lattice_size):\n",
    "    data = []\n",
    "    for _ in tqdm(range(num_samples), desc=\"Generating data\"):\n",
    "        p = np.random.uniform(0, 1)\n",
    "        lattice = generate_percolation_lattice(lattice_size, p)\n",
    "        lbl = check_percolation(lattice)\n",
    "        data.append((lattice, lbl))\n",
    "    return data\n",
    "\n",
    "def train_epoch(model, device, train_data, batch_size, optimizer, criterion, dim):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i in tqdm(range(0, len(train_data), batch_size), desc=\"Training\"):\n",
    "        batch = train_data[i : i + batch_size]\n",
    "        \n",
    "        # Extract lattices and labels\n",
    "        lattices = [torch.tensor(x, dtype=torch.float32) for x, _ in batch]\n",
    "        labels = [y for _, y in batch]\n",
    "        \n",
    "        # Stack into a (B, 1, H, W) tensor\n",
    "        inputs = torch.stack(lattices).unsqueeze(1).to(device)\n",
    "        targets = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, max_steps=MAX_STEPS)  # (B,) after .squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * len(batch)\n",
    "    \n",
    "    return running_loss / len(train_data)\n",
    "\n",
    "def test_systems(model, dim, power, device=\"cpu\", num_tests=10,\n",
    "                 system_size=\"standard\", p_range=(0, 1), verbose=True):\n",
    "    \"\"\"\n",
    "    Tests model on raw lattices without initial coarse-graining.\n",
    "    Args:\n",
    "        system_size: 'smaller' (dim^(power-1)), 'standard' (dim^power), or 'larger' (dim^(power+1))\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    size_power = {\n",
    "        \"smaller\": power - 1,\n",
    "        \"standard\": power,\n",
    "        \"larger\": power + 1\n",
    "    }[system_size]\n",
    "    \n",
    "    lattice_size = dim ** size_power\n",
    "    results = []\n",
    "    \n",
    "    for _ in tqdm(range(num_tests), desc=f\"Testing {lattice_size}x{lattice_size}\"):\n",
    "        p = np.random.uniform(*p_range)\n",
    "        lattice = generate_percolation_lattice(lattice_size, p)\n",
    "        true_label = check_percolation(lattice)\n",
    "        \n",
    "        input_tensor = torch.tensor(lattice, dtype=torch.float32)\n",
    "        input_tensor = input_tensor.unsqueeze(0).unsqueeze(0).to(device)  # [1,1,H,W]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(input_tensor).item()\n",
    "        \n",
    "        results.append((lattice, true_label, pred))\n",
    "    \n",
    "    threshold = 0.5\n",
    "    correct = sum(1 for _, lbl, pred in results if (pred > threshold) == lbl)\n",
    "    acc = correct / num_tests\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{lattice_size}x{lattice_size} Results:\")\n",
    "        print(f\"Accuracy: {acc:.2%}\")\n",
    "        print(f\"Avg prediction | Perc: {np.mean([p for _, l, p in results if l == 1]):.3f}\")\n",
    "        print(f\"Avg prediction | Non-Perc: {np.mean([p for _, l, p in results if l == 0]):.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38863cfc-7d8d-4a03-bf30-ba047b70e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SIZE = DIM ** POWER\n",
    "TRAIN_SAMPLES = 10000\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 5\n",
    "\n",
    "def run_experiment(DIM, POWER, run_num):\n",
    "    SIZE = DIM ** POWER\n",
    "    MAX_STEPS = POWER + 5\n",
    "    \n",
    "    # Generate training dataset\n",
    "    train_data = prepare_dataset(TRAIN_SAMPLES, SIZE)\n",
    "    \n",
    "    # Initialize model, optimizer, loss\n",
    "    model = PercolationModel(dim=DIM).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss = train_epoch(model, DEVICE, train_data, BATCH_SIZE, optimizer, criterion, DIM)\n",
    "\n",
    "    # Testing configurations\n",
    "    test_configs = [\n",
    "        {\"system_size\": \"smaller\", \"num_tests\": 100, \"p_range\": (0.1, 0.9)},\n",
    "        {\"system_size\": \"standard\", \"num_tests\": 100, \"p_range\": (0.1, 0.9)},\n",
    "        {\"system_size\": \"larger\", \"num_tests\": 100, \"p_range\": (0.1, 0.9)},\n",
    "        {\"system_size\": \"standard\", \"num_tests\": 200, \"p_range\": (0.58, 0.61)},\n",
    "    ]\n",
    "    \n",
    "    test_results = {}\n",
    "    for config in test_configs:\n",
    "        key = f\"{config['system_size']}_{config['p_range'][0]}-{config['p_range'][1]}\"\n",
    "        test_results[key] = test_systems(\n",
    "            model=model,\n",
    "            dim=DIM,\n",
    "            power=POWER,\n",
    "            device=DEVICE,\n",
    "            **config\n",
    "        )\n",
    "\n",
    "    # Summarize test results\n",
    "    summaries = {}\n",
    "    for key, results in test_results.items():\n",
    "        acc = sum((pred > 0.5) == lbl for _, lbl, pred in results) / len(results)\n",
    "        mean_perc = np.nanmean([pred for _, lbl, pred in results if lbl == 1])\n",
    "        mean_non_perc = np.nanmean([pred for _, lbl, pred in results if lbl == 0])\n",
    "        summaries[key] = (acc, mean_perc, mean_non_perc)\n",
    "\n",
    "    # Generate rule-projection data by feeding 3×3 patch of constant p\n",
    "    ps_coarse = np.linspace(0.0, 1.0, 101)\n",
    "    ps_fine = np.linspace(0.5, 0.7, 201)\n",
    "    ps = np.unique(np.concatenate((ps_coarse, ps_fine)))\n",
    "    ps.sort()\n",
    "\n",
    "    mean_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for p in ps:\n",
    "            # Create a single 3×3 patch with all entries = p\n",
    "            patch = np.full((DIM * DIM,), p, dtype=np.float32)        # shape: (dim*dim,)\n",
    "            patch_tensor = torch.from_numpy(patch).unsqueeze(0).to(DEVICE)  # (1, dim*dim)\n",
    "            out = model.rule(patch_tensor).cpu().numpy().item()        # scalar\n",
    "            mean_outputs.append(out)\n",
    "\n",
    "    return summaries, (ps, mean_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba5f7d-f3ff-486b-9013-3af22f332a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main experiment loop\n",
    "all_results = {}\n",
    "all_plots = {}\n",
    "combinations = [(3, 2), (3, 3), (3, 4), (4, 2), (4, 3), (4, 4)]\n",
    "n_runs = 10\n",
    "\n",
    "for DIM, POWER in combinations:\n",
    "    key = f\"{DIM}^{POWER}\"\n",
    "    all_results[key] = []\n",
    "    all_plots[key] = []\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        print(f\"\\nRunning {key} - Run {run+1}/{n_runs}\")\n",
    "        summaries, plot_data = run_experiment(DIM, POWER, run)\n",
    "        all_results[key].append(summaries)\n",
    "        all_plots[key].append(plot_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f90de0-4c1f-496e-9960-b311d4b9ff01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate consolidated PDF report\n",
    "with PdfPages(\"consolidated_results.pdf\") as pdf:\n",
    "    for DIM, POWER in combinations:\n",
    "        key = f\"{DIM}^{POWER}\"\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        fixed_points = []\n",
    "        \n",
    "        for run_idx, (ps, outputs) in enumerate(all_plots[key]):\n",
    "            plt.plot(ps, outputs, alpha=0.5, label=f\"Run {run_idx+1}\")\n",
    "            \n",
    "            # Find intersection with f(p) = p\n",
    "            diff = np.array(outputs) - np.array(ps)\n",
    "            sign_changes = np.where(np.diff(np.sign(diff)))[0]\n",
    "            \n",
    "            # For each sign change, find the approximate fixed point\n",
    "            run_fixed_points = []\n",
    "            for i in sign_changes:\n",
    "                if i+1 < len(ps):\n",
    "                    x0, x1 = ps[i], ps[i+1]\n",
    "                    y0, y1 = outputs[i], outputs[i+1]\n",
    "                    # Linear approximation of intersection\n",
    "                    t = (x0 - y0) / ((y1 - y0) - (x1 - x0))\n",
    "                    fixed_point = x0 + t * (x1 - x0)\n",
    "                    run_fixed_points.append(fixed_point)\n",
    "            \n",
    "            if run_fixed_points:\n",
    "                # Take the fixed point closest to the known critical point (~0.5927)\n",
    "                best_fp = min(run_fixed_points, key=lambda x: abs(x - 0.5927))\n",
    "                fixed_points.append(best_fp)\n",
    "                plt.scatter([best_fp], [best_fp], color='black', s=20)\n",
    "        \n",
    "        # Plot f(p) = p line\n",
    "        plt.plot([0, 1], [0, 1], color=\"black\", linestyle=\"--\", label=\"f(p) = p\")\n",
    "        \n",
    "        # Add mean fixed point if available\n",
    "        if fixed_points:\n",
    "            mean_fp = np.mean(fixed_points)\n",
    "            plt.plot(mean_fp, mean_fp, color='red', label=f\"Mean Fixed Point: {mean_fp:.4f}\")\n",
    "        \n",
    "        plt.title(f\"NFC Rule Projection - Configuration {key}\", fontsize=18)\n",
    "        plt.xlabel(\"Density (p)\", fontsize=14)\n",
    "        plt.ylabel(r\"$f_{\\theta}(p\\mathbf{1})$\", fontsize=14)\n",
    "        plt.legend(fontsize=12)\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "# Generate consolidated text report\n",
    "with open(\"consolidated_accuracies.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "    for DIM, POWER in combinations:\n",
    "        key = f\"{DIM}^{POWER}\"\n",
    "        \n",
    "        f.write(f\"\\n{'='*40}\\nConfiguration: {key}\\n{'='*40}\\n\")\n",
    "        \n",
    "        # Get fixed points for this configuration\n",
    "        config_fixed_points = []\n",
    "        for run_data in all_plots[key]:\n",
    "            ps, outputs = run_data\n",
    "            diff = np.array(outputs) - np.array(ps)\n",
    "            sign_changes = np.where(np.diff(np.sign(diff)))[0]\n",
    "            \n",
    "            run_fixed_points = []\n",
    "            for i in sign_changes:\n",
    "                if i+1 < len(ps):\n",
    "                    x0, x1 = ps[i], ps[i+1]\n",
    "                    y0, y1 = outputs[i], outputs[i+1]\n",
    "                    t = (x0 - y0) / ((y1 - y0) - (x1 - x0))\n",
    "                    fixed_point = x0 + t * (x1 - x0)\n",
    "                    run_fixed_points.append(fixed_point)\n",
    "            \n",
    "            if run_fixed_points:\n",
    "                best_fp = min(run_fixed_points, key=lambda x: abs(x - 0.5927))\n",
    "                config_fixed_points.append(best_fp)\n",
    "        \n",
    "        if config_fixed_points:\n",
    "            mean_fp = np.mean(config_fixed_points)\n",
    "            std_fp = np.std(config_fixed_points)\n",
    "            f.write(\"Fixed Points (intersection with f(p) = p):\\n\")\n",
    "            f.write(f\"  Values: {[f'{fp:.6f}' for fp in config_fixed_points]}\\n\")\n",
    "            f.write(f\"  Mean: {mean_fp:.6f} ± {std_fp:.6f}\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"No clear fixed points found (no intersection with f(p) = p)\\n\\n\")\n",
    "        \n",
    "        # Write accuracy information with full details for each test type\n",
    "        test_types = [\"smaller_0.1-0.9\", \"standard_0.1-0.9\", \"larger_0.1-0.9\", \"standard_0.58-0.61\"]\n",
    "        for test_type in test_types:\n",
    "            f.write(f\"{test_type.replace('_', ' ')}:\\n\")\n",
    "            \n",
    "            # Get all runs' results for this test type\n",
    "            all_runs_results = [run[test_type] for run in all_results[key]]\n",
    "            \n",
    "            # Write detailed accuracy for each run\n",
    "            for run_idx, (acc, mean_perc, mean_non_perc) in enumerate(all_runs_results):\n",
    "                f.write(f\"  Run {run_idx+1}:\\n\")\n",
    "                f.write(f\"    Accuracy: {acc:.4f}\\n\")\n",
    "                f.write(f\"    Avg prediction | Perc: {mean_perc:.4f}\\n\")\n",
    "                f.write(f\"    Avg prediction | Non-Perc: {mean_non_perc:.4f}\\n\")\n",
    "            \n",
    "            # Calculate and write summary statistics\n",
    "            accs = [x[0] for x in all_runs_results]\n",
    "            mean_percs = [x[1] for x in all_runs_results]\n",
    "            mean_non_percs = [x[2] for x in all_runs_results]\n",
    "            \n",
    "            f.write(\"\\n  Summary statistics:\\n\")\n",
    "            f.write(f\"    Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\\n\")\n",
    "            f.write(f\"    Avg prediction | Perc: {np.mean(mean_percs):.4f} ± {np.std(mean_percs):.4f}\\n\")\n",
    "            f.write(f\"    Avg prediction | Non-Perc: {np.mean(mean_non_percs):.4f} ± {np.std(mean_non_percs):.4f}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
