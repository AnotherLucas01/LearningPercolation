{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e6060-c069-4c88-8611-32794e639c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.ndimage import label\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "MAX_STEPS = 10\n",
    "\n",
    "def generate_percolation_lattice(size, p):\n",
    "    return np.random.choice([0, 1], (size, size), p=[1-p, p]).astype(np.uint8)\n",
    "\n",
    "def check_percolation(lattice):\n",
    "    labeled, _ = label(lattice)\n",
    "    top = set(labeled[0]) - {0}\n",
    "    bottom = set(labeled[-1]) - {0}\n",
    "    left = set(labeled[:,0]) - {0}\n",
    "    right = set(labeled[:,-1]) - {0}\n",
    "    return float(bool(top & bottom) or bool(left & right))\n",
    "\n",
    "def first_coarse_graining(binary_lattice, dim):\n",
    "    \"\"\"Average non-overlapping dim×dim blocks.\"\"\"\n",
    "    t = torch.tensor(binary_lattice, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    patches = F.unfold(t, kernel_size=dim, stride=dim)             # [1, dim*dim, num_patches]\n",
    "    patches = patches.permute(0, 2, 1)                             # [1, num_patches, dim*dim]\n",
    "    coarse_vals = patches.mean(dim=2)                             # [1, num_patches]\n",
    "    H, W = binary_lattice.shape\n",
    "    new_h, new_w = H // dim, W // dim\n",
    "    return coarse_vals.view(1, 1, new_h, new_w).squeeze(0)        # [1, new_h, new_w]\n",
    "\n",
    "class PercolationModel(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.rule = nn.Sequential(\n",
    "            nn.Linear(dim * dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, max_steps=MAX_STEPS):\n",
    "        b, c, H, W = x.shape\n",
    "        for _ in range(max_steps):\n",
    "            if H < self.dim or W < self.dim:\n",
    "                break\n",
    "            patches = F.unfold(x, kernel_size=self.dim, stride=self.dim)  # [b, dim*dim, np]\n",
    "            patches = patches.permute(0, 2, 1).contiguous()               # [b, np, dim*dim]\n",
    "            out = self.rule(patches.view(-1, self.dim*self.dim))          # [b*np, 1]\n",
    "            new_h, new_w = H // self.dim, W // self.dim\n",
    "            x = out.view(b, 1, new_h, new_w)\n",
    "            _, _, H, W = x.shape\n",
    "        return x.squeeze(1).view(b, -1)  # returns shape [b, new_h*new_w] or [b] if fully reduced\n",
    "\n",
    "def prepare_dataset(N, sizes):\n",
    "    data = []\n",
    "    for _ in tqdm(range(N), desc=\"Generating data\"):\n",
    "        p = np.random.uniform(0.1, 0.9)\n",
    "        size = np.random.choice(sizes)\n",
    "        L = generate_percolation_lattice(size, p)\n",
    "        data.append((L, check_percolation(L)))\n",
    "    return data\n",
    "\n",
    "def train_epoch(model, device, data, batch_size, opt, crit):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    # Process in batches, then split into size groups\n",
    "    for i in tqdm(range(0, len(data), batch_size), desc=\"Training\"):\n",
    "        batch = data[i:i+batch_size]\n",
    "        processed = []\n",
    "        # Apply first_coarse_graining and get sizes\n",
    "        for x, y in batch:\n",
    "            cg_lattice = first_coarse_graining(x, DIM)  # [1, H', W']\n",
    "            h, w = cg_lattice.shape[-2], cg_lattice.shape[-1]\n",
    "            processed.append((cg_lattice, y, (h, w)))\n",
    "        \n",
    "        # Group by size\n",
    "        groups = {}\n",
    "        for cg, y, size in processed:\n",
    "            if size not in groups:\n",
    "                groups[size] = []\n",
    "            groups[size].append((cg, y))\n",
    "        \n",
    "        # Process each group\n",
    "        group_loss = 0.0\n",
    "        for size_key, group in groups.items():\n",
    "            lattices = [item[0] for item in group]\n",
    "            labels = [item[1] for item in group]\n",
    "            inputs = torch.stack(lattices).to(device)  # [B, 1, H, W]\n",
    "            targets = torch.tensor(labels, dtype=torch.float32, device=device)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)  # [B, 1]\n",
    "            loss = crit(outputs.view(-1), targets)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            group_loss += loss.item() * len(group)\n",
    "        \n",
    "        total_loss += group_loss\n",
    "    \n",
    "    return total_loss / len(data)\n",
    "\n",
    "def test_systems(model, dim, power, device='cpu',\n",
    "                              num_tests=50, system_size='standard',\n",
    "                              p_range=(0,1), verbose=True):\n",
    "    \"\"\"\n",
    "    For each test:\n",
    "      1) generate a raw DIM^size_power × DIM^size_power lattice\n",
    "      2) compute true percolation label on that raw lattice\n",
    "      3) manually coarse-grain once (patch size = dim)\n",
    "      4) feed the result into model (which will do further recursive steps)\n",
    "    \"\"\"\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # Determine the exponent for lattice_size\n",
    "    size_power = {'3^2': power-1, '3^3': power, '3^4': power+1, '3^5': power+2, '3^6': power+3, '3^7': power+4}[system_size]\n",
    "    L = dim ** size_power\n",
    "\n",
    "    results = []\n",
    "    for _ in tqdm(range(num_tests), desc=f\"Testing {L}×{L}\"):\n",
    "        # 1) Raw lattice + label\n",
    "        p   = np.random.uniform(*p_range)\n",
    "        raw = generate_percolation_lattice(L, p)\n",
    "        lbl = check_percolation(raw)\n",
    "\n",
    "        # 2) Manual first coarse-graining\n",
    "        coarse = first_coarse_graining(raw, dim)   # tensor shape [1, L/dim, L/dim]\n",
    "\n",
    "        # 3) Prepare input for the model\n",
    "        inp = coarse.unsqueeze(0).to(device)       # [1, 1, L/dim, L/dim]\n",
    "\n",
    "        # 4) Get network prediction\n",
    "        with torch.no_grad():\n",
    "            # Let the model do its remaining recursion as usual\n",
    "            # (the `max_steps` is large enough that it will recurse until <dim)\n",
    "            out = model(inp).view(-1).item()\n",
    "\n",
    "        results.append((raw, lbl, out))\n",
    "\n",
    "    # Compute accuracy at 0.5 threshold\n",
    "    acc = sum((pred > 0.5) == lbl for _, lbl, pred in results) / num_tests\n",
    "\n",
    "    if verbose:\n",
    "        pos = [pred for _, lbl, pred in results if lbl==1]\n",
    "        neg = [pred for _, lbl, pred in results if lbl==0]\n",
    "        print(f\"\\nAfter manual first coarse-grain -> NN cascade on {L}×{L}:\")\n",
    "        print(f\" Accuracy        : {acc:.2%}\")\n",
    "        print(f\" Avg pred | Perc     : {np.mean(pos):.3f}\")\n",
    "        print(f\" Avg pred | Non-Perc : {np.mean(neg):.3f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- Run -----------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Add this configuration block (critical for model initialization)\n",
    "DIM = 3      # Patch size for coarse-graining (fixed for the model architecture)\n",
    "POWER = 3    # Base exponent for lattice sizes (3^POWER = 27x27 as \"standard\")\n",
    "SIZES = [DIM**2, DIM**3, DIM**4]  # Mixed training sizes: 9x9, 27x27, 81x81\n",
    "\n",
    "# Generate mixed-size training data\n",
    "train_data = prepare_dataset(20_000, SIZES)\n",
    "\n",
    "# Initialize model with DIM=3 (matches patch size used in first_coarse_graining)\n",
    "model = PercolationModel(DIM).to(DEVICE)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.BCELoss()\n",
    "\n",
    "# Training loop (unchanged)\n",
    "for epoch in range(1, 20):\n",
    "    loss = train_epoch(model, DEVICE, train_data, 10, opt, crit)\n",
    "    print(f\"Epoch {epoch} — Loss: {loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
